{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System : Python  2.7.12 | packaged by conda-forge | (default, Sep  8 2016, 14:22:31) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] \n",
      "\n",
      "\n",
      "Directory Structure:\n",
      "/home/ubuntu/ana_py27_p2/projects/CervicalCancer\n",
      ".\n",
      "├── unused_utils\n",
      "│   ├── __init__.py\n",
      "│   ├── __init__.pyc\n",
      "│   ├── utils.pyc\n",
      "│   └── unused_utils.py\n",
      "├── __init__.py\n",
      "├── 001 - Initial Setup.ipynb\n",
      "├── data\n",
      "│   ├── additional_Type_1_v2.7z\n",
      "│   ├── additional_Type_3_v2.7z\n",
      "│   ├── additional_Type_2_v2.7z\n",
      "│   ├── train\n",
      "│   │   ├── Type_1 [168 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── Type_2 [524 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── Type_3 [302 entries exceeds filelimit, not opening dir]\n",
      "│   ├── test\n",
      "│   │   └── unknown [512 entries exceeds filelimit, not opening dir]\n",
      "│   ├── preview\n",
      "│   ├── downloads\n",
      "│   │   ├── sample_submission.csv.zip\n",
      "│   │   ├── test.7z\n",
      "│   │   └── train.7z\n",
      "│   ├── valid\n",
      "│   │   ├── Type_1 [82 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── Type_2 [257 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── Type_3 [148 entries exceeds filelimit, not opening dir]\n",
      "│   ├── sample\n",
      "│   │   ├── preview\n",
      "│   │   ├── train\n",
      "│   │   │   ├── Type_1 [80 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   ├── Type_2 [249 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   └── Type_3 [144 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── valid\n",
      "│   │   │   ├── Type_1 [61 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   ├── Type_2 [191 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   └── Type_3 [110 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── test\n",
      "│   │   │   └── unknown [201 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── weights\n",
      "│   │       ├── weights-improvement-00-0.22.hdf5\n",
      "│   │       ├── weights-improvement-01-0.35.hdf5\n",
      "│   │       ├── weights-improvement-03-0.36.hdf5\n",
      "│   │       ├── weights-improvement-06-0.45.hdf5\n",
      "│   │       ├── weights-improvement-07-0.47.hdf5\n",
      "│   │       ├── BaseCNN35EpochRun_1.hdf5\n",
      "│   │       ├── weights2-improvement-00-0.30.hdf5\n",
      "│   │       ├── weights2-improvement-01-0.37.hdf5\n",
      "│   │       ├── weights2-improvement-05-0.43.hdf5\n",
      "│   │       ├── weights2-improvement-11-0.46.hdf5\n",
      "│   │       └── weights2-improvement-12-0.50.hdf5\n",
      "│   ├── submissions\n",
      "│   │   ├── sample_submission_000.csv\n",
      "│   │   ├── sub_001.csv\n",
      "│   │   ├── sub_002.csv\n",
      "│   │   ├── sub_003.csv\n",
      "│   │   ├── sub_004.csv\n",
      "│   │   └── sub_005.csv\n",
      "│   └── weights [22 entries exceeds filelimit, not opening dir]\n",
      "├── 002 - Data Setup & General Notes.ipynb\n",
      "├── 003 - Baseline.ipynb\n",
      "├── Trash\n",
      "│   ├── 002-01 - Train Data (only) Setup.ipynb\n",
      "│   └── Base CNN Model Train Data with Preprocessing.ipynb\n",
      "├── Gradient Boosting Classifier.ipynb\n",
      "├── 004-1 - Base CNN Model - Sample.ipynb\n",
      "├── 004-2 - Base CNN Model - Train Data.ipynb\n",
      "├── 005 - Exploratoring the Data.ipynb\n",
      "└── Non Neural Net Classifiers.ipynb\n",
      "\n",
      "30 directories, 38 files\n",
      "\n",
      "\n",
      "Keras version: 2.0.2 , backend: theano , image_format: channels_last\n",
      "\n",
      "\n",
      "Environment : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='../../ana_py27_p2.yml' target='_blank'>../../ana_py27_p2.yml</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/ana_py27_p2/ana_py27_p2.yml"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project Template Import Cell\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from inspect import getsourcefile\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Standard Notebook Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CURR_PATH = os.path.abspath(getsourcefile(lambda:0)).rsplit('/', 1)[0] # Get filepath of this notebook\n",
    "module_path = os.path.join(os.path.dirname(CURR_PATH), 'utils') # Make module path for one dir up and one down into utils\n",
    "if module_path not in sys.path: # Append to system path list\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils as utils ; reload(utils)\n",
    "\n",
    "print('System : Python ', os.sys.version , '\\n\\n')\n",
    "\n",
    "print('Directory Structure:')\n",
    "print(CURR_PATH)\n",
    "!tree -cn --filelimit 12\n",
    "\n",
    "# Keras Setup\n",
    "import keras\n",
    "print('\\n\\nKeras version:' , keras.__version__ ,\n",
    "      ', backend:' , keras.backend.backend(),\n",
    "      ', image_format:' , keras.backend.image_data_format())\n",
    "\n",
    "random_seed = 2\n",
    "\n",
    "print('\\n\\nEnvironment : ')\n",
    "FileLink('../../ana_py27_p2.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A fix for truncated image error\n",
    "# http://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\n",
    "# http://opencv-python-tutroals.readthedocs.io/\n",
    "#                                 en/latest/py_tutorials/py_ml/py_knn/py_knn_opencv/py_knn_opencv.html#knn-opencv\n",
    "import cv2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier # Use after a few classifiers have been selected\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images\n",
      "201\n",
      "['data/sample/test/unknown/3_1409.jpg', 'data/sample/test/unknown/2_1046.jpg', 'data/sample/test/unknown/2_933.jpg', 'data/sample/test/unknown/2_1407.jpg']\n",
      "Classified Images\n",
      "835\n",
      "['data/sample/train/Type_2/905.jpg', 'data/sample/train/Type_2/1180.jpg', 'data/sample/train/Type_2/777.jpg', 'data/sample/train/Type_2/1313.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Get Image Paths\n",
    "\n",
    "# !!!SAMPLE\n",
    "train_data_dir = 'data/sample/train' ; validation_data_dir = 'data/sample/valid' ; test_data_dir = 'data/sample/test'\n",
    "weights_dir = 'data/sample/weights'\n",
    "\n",
    "# !!!TRAIN\n",
    "#train_data_dir = 'data/train' ; validation_data_dir = 'data/valid' ; test_data_dir = 'data/test' \n",
    "#weights_dir = 'data/weights' ; submission_dir = 'data/submissions'\n",
    "\n",
    "# Make a list of test_image_paths\n",
    "test_image_paths = utils.get_non_hidden_dir_contents(os.path.join(test_data_dir, 'unknown'))\n",
    "print('Test Images')\n",
    "print(len(test_image_paths))\n",
    "print(test_image_paths[0:4])\n",
    "\n",
    "\n",
    "# Make a list of all classified image paths\n",
    "data_dirs = utils.get_non_hidden_dir_contents(train_data_dir)\n",
    "data_dirs.extend(utils.get_non_hidden_dir_contents(validation_data_dir))\n",
    "# Make a nested list and flatten it\n",
    "full_image_paths = sum([[image_path for image_path in utils.get_non_hidden_dir_contents(data_dir)] \n",
    "                       for data_dir in data_dirs],[])\n",
    "print('Classified Images')\n",
    "print(len(full_image_paths))\n",
    "print(full_image_paths[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                path  Type\n",
      "0   data/sample/train/Type_2/905.jpg     1\n",
      "1  data/sample/train/Type_2/1180.jpg     1\n",
      "                                 path  Type\n",
      "833  data/sample/valid/Type_1/783.jpg     0\n",
      "834   data/sample/valid/Type_1/57.jpg     0\n"
     ]
    }
   ],
   "source": [
    "# Make a DataFrame for convenience\n",
    "data_df = pd.DataFrame(full_image_paths, columns =['path'])\n",
    "data_df['Type'] = data_df['path'].apply(lambda x: int(x.split('/')[-2].split('_')[1])-1)\n",
    "\n",
    "print(data_df.head(2))\n",
    "print(data_df.tail(2))\n",
    "# Shuffle the DataFrame before taking a sample\n",
    "data_df = data_df.sample(frac=1,random_state=random_seed)\n",
    "\n",
    "\n",
    "# Take sample\n",
    "#data_df = data_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sample/valid/Type_1/751.jpg\n",
      "[0 1 2 2]\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Split into Train & Test Samples\n",
    "X = data_df['path'].values\n",
    "y = data_df['Type'].values\n",
    "skf = StratifiedKFold(y, shuffle=True, n_folds = 10, random_state=random_seed)\n",
    "print(X[0:1][0])\n",
    "print(y[0:4])\n",
    "hsv = cv2.imread(X[0:1][0])\n",
    "print(type(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3.119047619047619, 1: 1.0, 2: 1.7350993377483444}\n"
     ]
    }
   ],
   "source": [
    "class_weight_dict = utils.get_class_weight_dict([168, 524, 302])\n",
    "print(class_weight_dict) # = {1: 3.03, 2: 1.0, 3: 1.71}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/31259891/put-customized-functions-in-sklearn-pipeline\n",
    "# Feature extraction function\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Extract_Color_Histogram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bin_s = 8, size=32):\n",
    "        self.bin_s = bin_s\n",
    "        self.size=size\n",
    "    def transform(self, X, *_):\n",
    "        \"\"\"\n",
    "        Accepts X a numpy array of image paths\n",
    "        cv2.resize(img, (32,32).flatten()\n",
    "        \n",
    "        \"\"\"\n",
    "        # To store data as it is being generated\n",
    "        X_data = []\n",
    "        for image_path in X:\n",
    "            img_array = cv2.imread(image_path)#, cv2.COLOR_BGR2HSV)\n",
    "            # Resize downwards\n",
    "            img_array = cv2.resize(img_array, (self.size,self.size))\n",
    "            # Convert to hsv space\n",
    "            hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)\n",
    "            # Get the hsv histograms\n",
    "            hist = cv2.calcHist([hsv], [0,1,2], None, (self.bin_s,self.bin_s,self.bin_s), [0, 180, 0, 256, 0,256])\n",
    "            # Normalize the histograms\n",
    "            cv2.normalize(hist, hist)\n",
    "            # Flatten the histograms\n",
    "            X_data.append(hist.flatten())\n",
    "        ret_array = np.array(X_data)\n",
    "        return ret_array\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "etc_estimators = []\n",
    "etc_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "etc_estimators.append(('ExtraTreesClassifier', ExtraTreesClassifier(criterion='gini',\n",
    "                                                                n_estimators=20,\n",
    "                                                                oob_score = True,\n",
    "                                                                bootstrap=True, \n",
    "                                                                n_jobs=-1,\n",
    "                                                                class_weight='balanced_subsample',\n",
    "                                                                random_state = random_seed)))\n",
    "etc_clf = Pipeline(etc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "svc_estimators = []\n",
    "svc_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "svc_estimators.append(('SVC', SVC(C = 0.01,\n",
    "                                  kernel='rbf',\n",
    "                                  degree = 3,\n",
    "                                  probability=True,\n",
    "                                  decision_function_shape='ovr', \n",
    "                                  class_weight=class_weight_dict,\n",
    "                                  random_state = random_seed)))\n",
    "svc_clf = Pipeline(svc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "knn_estimators = []\n",
    "knn_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "knn_estimators.append(('SVC', KNeighborsClassifier(n_neighbors = 5,\n",
    "                                                   weights='distance',\n",
    "                                                   algorithm='auto',\n",
    "                                                   n_jobs = -1)))\n",
    "knn_clf = Pipeline(knn_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "gnb_estimators = []\n",
    "gnb_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "gnb_estimators.append(('GNB', GaussianNB()))\n",
    "gnb_clf = Pipeline(gnb_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "rfc_estimators = []\n",
    "rfc_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "rfc_estimators.append(('RFC', RandomForestClassifier(n_estimators=20,\n",
    "                                                     criterion='entropy',\n",
    "                                                     random_state=random_seed,\n",
    "                                                     warm_start=True,\n",
    "                                                     class_weight = class_weight_dict,\n",
    "                                                     bootstrap=True,\n",
    "                                                     oob_score=True,\n",
    "                                                     n_jobs = -1)))\n",
    "rcf_clf = Pipeline(rfc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "gbc_estimators = []\n",
    "gbc_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "gbc_estimators.append(('RFC', GradientBoostingClassifier(loss='deviance',\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         n_estimators=20,\n",
    "                                                         max_depth=3,\n",
    "                                                         max_features='auto',\n",
    "                                                         warm_start=True,\n",
    "                                                         random_state=random_seed)))\n",
    "gbc_clf = Pipeline(gbc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this for preliminary timing on the AWS p2 instance, so can estimate a good size for the sample directory files\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part Completed [ 0.5294  0.5595  0.5476  0.5357  0.5301  0.5904  0.5663  0.5663  0.5783\n",
      "  0.5422]\n",
      "Part Completed [ 0.5176  0.1667  0.1667  0.1667  0.3012  0.3012  0.3012  0.3012  0.3012\n",
      "  0.3012]\n",
      "Part Completed [ 0.4471  0.4286  0.5952  0.619   0.4458  0.5422  0.5181  0.5783  0.506\n",
      "  0.5301]\n",
      "Part Completed [ 0.3647  0.3452  0.3452  0.4167  0.3133  0.4337  0.3373  0.4458  0.4096\n",
      "  0.3012]\n",
      "Part Completed [ 0.5647  0.5119  0.619   0.6071  0.4337  0.5542  0.5181  0.5904  0.5663\n",
      "  0.4819]\n",
      "Part Completed [ 0.5765  0.4643  0.5833  0.5476  0.3976  0.5422  0.5663  0.5422  0.6145\n",
      "  0.5783]\n"
     ]
    }
   ],
   "source": [
    "all_names = ['ETC', 'SVC', 'KNN', 'GNB', 'RCF', 'GBC']\n",
    "all_results = []\n",
    "all_results.append(cross_val_score(etc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(svc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(knn_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(gnb_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(rcf_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(gbc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAHTCAYAAAD1WY1ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQYAAOg9wQYAAOi9/x8egPVjib1csAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf2acc6e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Learner Accuracy Scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(all_results)\n",
    "ax.set_xticklabels(all_names)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10636.559404 seconds\n",
      "Total Images Processed 835\n"
     ]
    }
   ],
   "source": [
    "# Use this for preliminary timing on the AWS p2 instance, so can estimate a good size for the sample directory files\n",
    "print(\"%f seconds\" % (time.time() - start_time))\n",
    "print('Total Images Processed %d'  % y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ana_py27_p2]",
   "language": "python",
   "name": "conda-env-ana_py27_p2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
