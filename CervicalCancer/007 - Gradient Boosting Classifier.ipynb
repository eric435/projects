{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System : Python  2.7.12 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:42:40) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] \n",
      "\n",
      "\n",
      "Directory Structure:\n",
      "/media/david/5C14F53A14F517AA/code/ana_py27_p2/projects/CervicalCancer_\n",
      ".\n",
      "├── 001 - Initial Setup.ipynb\n",
      "├── 002 - Sample Setup.ipynb\n",
      "├── 003 - Baseline.ipynb\n",
      "├── 004 - Base CNN Model.ipynb\n",
      "├── resources\n",
      "│   ├── TMI_CERVIX_v28n3_2009.pdf\n",
      "│   ├── Cervix types clasification(1).pdf\n",
      "│   └── Joe Minichino, Joseph Howse-Learning OpenCV 3 Computer Vision with Python-Packt Publishing (2015).epub\n",
      "├── reports\n",
      "├── data\n",
      "│   ├── train\n",
      "│   │   ├── Type_1 [250 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── Type_2 [781 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── Type_3 [450 entries exceeds filelimit, not opening dir]\n",
      "│   ├── test\n",
      "│   │   └── unknown [512 entries exceeds filelimit, not opening dir]\n",
      "│   ├── preview\n",
      "│   ├── results\n",
      "│   ├── sample\n",
      "│   │   ├── results\n",
      "│   │   ├── train\n",
      "│   │   │   ├── Type_1 [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   ├── Type_2 [106 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   └── Type_3 [62 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── valid\n",
      "│   │   │   ├── Type_1\n",
      "│   │   │   │   ├── 180.jpg\n",
      "│   │   │   │   ├── 191.jpg\n",
      "│   │   │   │   ├── 342.jpg\n",
      "│   │   │   │   ├── 416.jpg\n",
      "│   │   │   │   ├── 446.jpg\n",
      "│   │   │   │   ├── 739.jpg\n",
      "│   │   │   │   ├── 7.jpg\n",
      "│   │   │   │   ├── 1139.jpg\n",
      "│   │   │   │   ├── 1336.jpg\n",
      "│   │   │   │   ├── 218.jpg\n",
      "│   │   │   │   ├── 346.jpg\n",
      "│   │   │   │   └── 47.jpg\n",
      "│   │   │   ├── Type_2 [39 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   └── Type_3 [22 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── test\n",
      "│   │   │   └── unknown [20 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── preview [35 entries exceeds filelimit, not opening dir]\n",
      "│   ├── valid\n",
      "│   │   ├── Type_1\n",
      "│   │   ├── Type_2\n",
      "│   │   └── Type_3\n",
      "│   ├── downloads\n",
      "│   │   ├── sample_submission.csv.zip\n",
      "│   │   ├── test.7z\n",
      "│   │   ├── train.7z\n",
      "│   │   ├── removed_files.csv\n",
      "│   │   └── fixed_labels_v2.csv\n",
      "│   ├── sample1\n",
      "│   │   ├── preview [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── results\n",
      "│   │   ├── test\n",
      "│   │   │   └── unknown [20 entries exceeds filelimit, not opening dir]\n",
      "│   │   ├── train\n",
      "│   │   │   ├── Type_1 [35 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   ├── Type_2 [106 entries exceeds filelimit, not opening dir]\n",
      "│   │   │   └── Type_3 [62 entries exceeds filelimit, not opening dir]\n",
      "│   │   └── valid\n",
      "│   │       ├── Type_1\n",
      "│   │       │   ├── 416.jpg\n",
      "│   │       │   ├── 739.jpg\n",
      "│   │       │   ├── 7.jpg\n",
      "│   │       │   ├── 342.jpg\n",
      "│   │       │   ├── 180.jpg\n",
      "│   │       │   ├── 191.jpg\n",
      "│   │       │   ├── 446.jpg\n",
      "│   │       │   ├── 1139.jpg\n",
      "│   │       │   ├── 1336.jpg\n",
      "│   │       │   ├── 218.jpg\n",
      "│   │       │   ├── 346.jpg\n",
      "│   │       │   └── 47.jpg\n",
      "│   │       ├── Type_2 [39 entries exceeds filelimit, not opening dir]\n",
      "│   │       └── Type_3 [22 entries exceeds filelimit, not opening dir]\n",
      "│   └── submissions\n",
      "│       ├── sub_001.csv\n",
      "│       ├── sub_002.csv\n",
      "│       ├── sample_submission_000.csv\n",
      "│       ├── sub_006.csv\n",
      "│       └── sub_007.csv\n",
      "├── 005 - Exploratoring the Data.ipynb\n",
      "├── Base CNN Model Train Data with Preprocessing.ipynb\n",
      "├── aws_downloads\n",
      "│   ├── 004+-+Base+CNN+Model+Sample.html\n",
      "│   ├── 004+-+Base+CNN+Model+-+Train+Data.html\n",
      "│   ├── 004+-+Base+CNN+Model+-+Train+Data.zip\n",
      "│   ├── 002+-+Sample+Setup.html\n",
      "│   ├── Base+CNN+Model+Train+Data+with+Preprocessing_1.html\n",
      "│   └── Base+CNN+Model+Train+Data+with+Preprocessing_1.zip\n",
      "├── K-NN Classifier.ipynb\n",
      "├── Non Neural Net Classifiers.ipynb\n",
      "└── Gradient Boosting Classifier.ipynb\n",
      "\n",
      "44 directories, 52 files\n",
      "\n",
      "\n",
      "Keras version: 2.0.2 , backend: theano , image_format: channels_last\n",
      "\n",
      "\n",
      "Environment : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='../../ana_py27_p2.yml' target='_blank'>../../ana_py27_p2.yml</a><br>"
      ],
      "text/plain": [
       "/media/david/5C14F53A14F517AA/code/ana_py27_p2/ana_py27_p2.yml"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project Template Import Cell\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from inspect import getsourcefile\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Standard Notebook Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CURR_PATH = os.path.abspath(getsourcefile(lambda:0)).rsplit('/', 1)[0] # Get filepath of this notebook\n",
    "module_path = os.path.join(os.path.dirname(CURR_PATH), 'utils') # Make module path for one dir up and one down into utils\n",
    "if module_path not in sys.path: # Append to system path list\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils as utils ; reload(utils)\n",
    "\n",
    "print('System : Python ', os.sys.version , '\\n\\n')\n",
    "\n",
    "print('Directory Structure:')\n",
    "print(CURR_PATH)\n",
    "!tree -cn --filelimit 13\n",
    "\n",
    "# Keras Setup\n",
    "import keras\n",
    "print('\\n\\nKeras version:' , keras.__version__ ,\n",
    "      ', backend:' , keras.backend.backend(),\n",
    "      ', image_format:' , keras.backend.image_data_format())\n",
    "\n",
    "random_seed = 2\n",
    "\n",
    "print('\\n\\nEnvironment : ')\n",
    "FileLink('../../ana_py27_p2.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A fix for truncated image error\n",
    "# http://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\n",
    "# http://opencv-python-tutroals.readthedocs.io/\n",
    "#                                 en/latest/py_tutorials/py_ml/py_knn/py_knn_opencv/py_knn_opencv.html#knn-opencv\n",
    "import cv2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images\n",
      "20\n",
      "['data/sample/test/unknown/1_142.jpg', 'data/sample/test/unknown/1_531.jpg', 'data/sample/test/unknown/1_921.jpg', 'data/sample/test/unknown/2_1042.jpg']\n",
      "Classified Images\n",
      "276\n",
      "['data/sample/train/Type_1/396.jpg', 'data/sample/train/Type_1/0.jpg', 'data/sample/train/Type_1/102.jpg', 'data/sample/train/Type_1/1024.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Get Image Paths\n",
    "\n",
    "# !!!SAMPLE\n",
    "train_data_dir = 'data/sample/train' ; validation_data_dir = 'data/sample/valid' ; test_data_dir = 'data/sample/test'\n",
    "weights_dir = 'data/sample/weights'\n",
    "\n",
    "# !!!TRAIN\n",
    "#train_data_dir = 'data/train' ; validation_data_dir = 'data/valid' ; test_data_dir = 'data/test' \n",
    "#weights_dir = 'data/weights' ; submission_dir = 'data/submissions'\n",
    "\n",
    "# Make a list of test_image_paths\n",
    "test_image_paths = utils.get_non_hidden_dir_contents(os.path.join(test_data_dir, 'unknown'))\n",
    "print('Test Images')\n",
    "print(len(test_image_paths))\n",
    "print(test_image_paths[0:4])\n",
    "\n",
    "\n",
    "# Make a list of all classified image paths\n",
    "data_dirs = utils.get_non_hidden_dir_contents(train_data_dir)\n",
    "data_dirs.extend(utils.get_non_hidden_dir_contents(validation_data_dir))\n",
    "# Make a nested list and flatten it\n",
    "full_image_paths = sum([[image_path for image_path in utils.get_non_hidden_dir_contents(data_dir)] \n",
    "                       for data_dir in data_dirs],[])\n",
    "print('Classified Images')\n",
    "print(len(full_image_paths))\n",
    "print(full_image_paths[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               path  Type\n",
      "0  data/sample/train/Type_1/396.jpg     1\n",
      "1    data/sample/train/Type_1/0.jpg     1\n",
      "                                 path  Type\n",
      "274  data/sample/valid/Type_3/746.jpg     3\n",
      "275  data/sample/valid/Type_3/811.jpg     3\n"
     ]
    }
   ],
   "source": [
    "# Make a DataFrame for convenience\n",
    "data_df = pd.DataFrame(full_image_paths, columns =['path'])\n",
    "data_df['Type'] = data_df['path'].apply(lambda x: int(x.split('/')[-2].split('_')[1]))\n",
    "\n",
    "print(data_df.head(2))\n",
    "print(data_df.tail(2))\n",
    "\n",
    "# Shuffle the DataFrame before taking a sample\n",
    "data_df = data_df.sample(frac=1,random_state=random_seed)\n",
    "\n",
    "# Take sample\n",
    "#data_df = data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sample/train/Type_3/1275.jpg\n",
      "[3 1 2 1]\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Split into Train & Test Samples\n",
    "X = data_df['path'].values\n",
    "y = data_df['Type'].values\n",
    "skf = StratifiedKFold(y, shuffle=True, n_folds = 3, random_state=random_seed)\n",
    "print(X[0:1][0])\n",
    "print(y[0:4])\n",
    "hsv = cv2.imread(X[0:1][0])\n",
    "print(type(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class_weight_dict = utils.get_class_weight_dict([35, 106, 62])\n",
    "class_weight_dict = {1: 3.03, 2: 1.0, 3: 1.71}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/31259891/put-customized-functions-in-sklearn-pipeline\n",
    "# Feature extraction function\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Extract_Color_Histogram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bin_s = 8, size=64):\n",
    "        self.bin_s = bin_s\n",
    "        self.size=size\n",
    "    def transform(self, X, *_):\n",
    "        \"\"\"\n",
    "        Accepts X a numpy array of image paths\n",
    "        cv2.resize(img, (32,32).flatten()\n",
    "        \n",
    "        \"\"\"\n",
    "        # To store data as it is being generated\n",
    "        X_data = []\n",
    "        for image_path in X:\n",
    "            img_array = cv2.imread(image_path)#, cv2.COLOR_BGR2HSV)\n",
    "            # Resize downwards\n",
    "            img_array = cv2.resize(img_array, (self.size,self.size))\n",
    "            # Convert to hsv space\n",
    "            hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)\n",
    "            # Get the hsv histograms\n",
    "            hist = cv2.calcHist([hsv], [0,1,2], None, (self.bin_s,self.bin_s,self.bin_s), [0, 180, 0, 256, 0,256])\n",
    "            # Normalize the histograms\n",
    "            cv2.normalize(hist, hist)\n",
    "            # Flatten the histograms\n",
    "            X_data.append(hist.flatten())\n",
    "        ret_array = np.array(X_data)\n",
    "        return ret_array\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "gbc_estimators = []\n",
    "gbc_estimators.append(('Extract_Color_Histogram', Extract_Color_Histogram()))\n",
    "gbc_estimators.append(('GBC', GradientBoostingClassifier(loss='deviance',\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         n_estimators=100,\n",
    "                                                         max_depth=3,\n",
    "                                                         max_features='auto',\n",
    "                                                         warm_start=True,\n",
    "                                                         random_state=random_seed)))\n",
    "gbc_clf = Pipeline(gbc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this for preliminary timing on the AWS p2 instance, so can estimate a good size for the sample directory files\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBC__max_features',\n",
       " 'GBC__min_samples_leaf',\n",
       " 'GBC',\n",
       " 'GBC__random_state',\n",
       " 'GBC__init',\n",
       " 'Extract_Color_Histogram__size',\n",
       " 'GBC__learning_rate',\n",
       " 'GBC__subsample',\n",
       " 'GBC__warm_start',\n",
       " 'GBC__max_depth',\n",
       " 'GBC__presort',\n",
       " 'GBC__loss',\n",
       " 'Extract_Color_Histogram__bin_s',\n",
       " 'GBC__verbose',\n",
       " 'GBC__min_samples_split',\n",
       " 'steps',\n",
       " 'Extract_Color_Histogram',\n",
       " 'GBC__max_leaf_nodes',\n",
       " 'GBC__min_weight_fraction_leaf',\n",
       " 'GBC__n_estimators']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rates=np.array([1.0,0.1,0.01,0.001])\n",
    "max_features = np.array(['auto','sqrt'])\n",
    "sizes = np.array([32,64,128])\n",
    "bins = np.array([8,16,32])\n",
    "param_grid=dict(GBC__learning_rate=learning_rates,\n",
    "               Extract_Color_Histogram__size = sizes,\n",
    "               GBC__max_features=max_features,\n",
    "               Extract_Color_Histogram__bin_s=bins)\n",
    "grid = GridSearchCV(estimator=gbc_clf, param_grid=param_grid,n_jobs=-1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(grid.grid_scores_)\n",
    "print('\\n')\n",
    "print('Best Score: ' , grid.best_score_)\n",
    "print('\\n')\n",
    "#print(grid.best_estimator_.get_params()['GBC__learning_rate'])\n",
    "#print(grid.best_estimator_.get_params())\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use this for preliminary timing on the AWS p2 instance, so can estimate a good size for the sample directory files\n",
    "print(\"%f seconds\" % (time.time() - start_time))\n",
    "print('Total Images Processed %d'  % y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_names = ['ETC', 'SVC', 'KNN', 'GNB', 'RCF', 'GBC']\n",
    "all_results = []\n",
    "all_results.append(cross_val_score(etc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(svc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(knn_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(gnb_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(rcf_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])\n",
    "all_results.append(cross_val_score(gbc_clf, X, y, cv=skf))\n",
    "print('Part Completed', all_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Learner Accuracy Scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(all_results)\n",
    "ax.set_xticklabels(all_names)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ana_py27_p2]",
   "language": "python",
   "name": "conda-env-ana_py27_p2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
